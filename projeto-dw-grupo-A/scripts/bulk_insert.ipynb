{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11382300-0a32-4ca0-9b1b-6bb490548486",
   "metadata": {},
   "outputs": [],
   "source": [
    "import connection as cn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3a377f1-afd2-4dd9-bf54-80fa3425f1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "con = cn.get_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd6d1c63-ab6d-435d-a6c3-1455f664c466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.orm.session.Session at 0x26ce859d400>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b6dcda8-b224-4991-9814-f2d92fe46865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dim_date', 'dim_seller', 'dim_product', 'dim_customer', 'fact_sales', 'df_orders', 'df_items']\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import text\n",
    "\n",
    "sql = text(\"SELECT tablename FROM pg_catalog.pg_tables WHERE schemaname = 'analytics';\")\n",
    "result = con.execute(sql)\n",
    "\n",
    "tabelas = [row[0] for row in result]\n",
    "print(tabelas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b0fe645-c664-472d-bde1-45097018cfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_orders = pd.read_csv(\"../data/olist_orders_dataset.csv\")\n",
    "df_customers = pd.read_csv(\"../data/olist_customers_dataset.csv\")\n",
    "df_items = pd.read_csv(\"../data/olist_order_items_dataset.csv\")\n",
    "df_products = pd.read_csv(\"../data/olist_products_dataset.csv\")\n",
    "df_sellers = pd.read_csv(\"../data/olist_sellers_dataset.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab6fd005-26d0-4239-ab94-dce8c4577e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conectado ao banco!\n",
      "Lendo: C:\\Users\\mmsantos\\Downloads\\db p2\\P2-BDA-\\projeto-dw-grupo-A\\data\\olist_orders_dataset.csv\n",
      "Tabela temporÃ¡ria analytics.df_orders criada!\n"
     ]
    },
    {
     "ename": "IntegrityError",
     "evalue": "(psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint \"dim_date_pkey\"\nDETAIL:  Key (date_sk)=(1) already exists.\n\n[SQL: \n        INSERT INTO analytics.dim_date (\n            date_sk, full_date, year, month, day,\n            day_of_week, month_name, day_name\n        )\n        SELECT\n            ROW_NUMBER() OVER (ORDER BY full_date_clean),\n            full_date_clean,\n            EXTRACT(YEAR FROM full_date_clean),\n            EXTRACT(MONTH FROM full_date_clean),\n            EXTRACT(DAY FROM full_date_clean),\n            EXTRACT(DOW FROM full_date_clean) + 1,\n            TO_CHAR(full_date_clean, 'Month'),\n            TO_CHAR(full_date_clean, 'Day')\n        FROM (\n            SELECT DISTINCT DATE_TRUNC('day', order_purchase_timestamp::timestamp)\n            AS full_date_clean\n            FROM analytics.df_orders\n        ) AS unique_dates;\n    ]\n(Background on this error at: https://sqlalche.me/e/20/gkpj)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUniqueViolation\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1967\u001b[39m, in \u001b[36mConnection._exec_single_context\u001b[39m\u001b[34m(self, dialect, context, statement, parameters)\u001b[39m\n\u001b[32m   1966\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[32m-> \u001b[39m\u001b[32m1967\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdo_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1968\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[32m   1969\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1971\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.engine._has_events:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sqlalchemy\\engine\\default.py:951\u001b[39m, in \u001b[36mDefaultDialect.do_execute\u001b[39m\u001b[34m(self, cursor, statement, parameters, context)\u001b[39m\n\u001b[32m    950\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m951\u001b[39m     \u001b[43mcursor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mUniqueViolation\u001b[39m: duplicate key value violates unique constraint \"dim_date_pkey\"\nDETAIL:  Key (date_sk)=(1) already exists.\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mIntegrityError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 67\u001b[39m\n\u001b[32m     64\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTabela temporÃ¡ria removida!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m     \u001b[43mload_dim_date\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 56\u001b[39m, in \u001b[36mload_dim_date\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     34\u001b[39m insert_sql = text(\u001b[33m\"\"\"\u001b[39m\n\u001b[32m     35\u001b[39m \u001b[33m    INSERT INTO analytics.dim_date (\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[33m        date_sk, full_date, year, month, day,\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     52\u001b[39m \u001b[33m    ) AS unique_dates;\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[33m\u001b[39m\u001b[33m\"\"\"\u001b[39m)\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m engine.begin() \u001b[38;5;28;01mas\u001b[39;00m conn:\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m     \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43minsert_sql\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mdim_date populada com sucesso!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     60\u001b[39m \u001b[38;5;66;03m# 4. Remover tabela temporÃ¡ria\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1419\u001b[39m, in \u001b[36mConnection.execute\u001b[39m\u001b[34m(self, statement, parameters, execution_options)\u001b[39m\n\u001b[32m   1417\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc.ObjectNotExecutableError(statement) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   1418\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1419\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1420\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1421\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1422\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mNO_OPTIONS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1423\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sqlalchemy\\sql\\elements.py:526\u001b[39m, in \u001b[36mClauseElement._execute_on_connection\u001b[39m\u001b[34m(self, connection, distilled_params, execution_options)\u001b[39m\n\u001b[32m    524\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[32m    525\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, Executable)\n\u001b[32m--> \u001b[39m\u001b[32m526\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execute_clauseelement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    527\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistilled_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecution_options\u001b[49m\n\u001b[32m    528\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    529\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    530\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc.ObjectNotExecutableError(\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1641\u001b[39m, in \u001b[36mConnection._execute_clauseelement\u001b[39m\u001b[34m(self, elem, distilled_parameters, execution_options)\u001b[39m\n\u001b[32m   1629\u001b[39m compiled_cache: Optional[CompiledCacheType] = execution_options.get(\n\u001b[32m   1630\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcompiled_cache\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m.engine._compiled_cache\n\u001b[32m   1631\u001b[39m )\n\u001b[32m   1633\u001b[39m compiled_sql, extracted_params, cache_hit = elem._compile_w_cache(\n\u001b[32m   1634\u001b[39m     dialect=dialect,\n\u001b[32m   1635\u001b[39m     compiled_cache=compiled_cache,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1639\u001b[39m     linting=\u001b[38;5;28mself\u001b[39m.dialect.compiler_linting | compiler.WARN_LINTING,\n\u001b[32m   1640\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1641\u001b[39m ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1642\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1643\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecution_ctx_cls\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_init_compiled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1644\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompiled_sql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1645\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1646\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1647\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompiled_sql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1648\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1649\u001b[39m \u001b[43m    \u001b[49m\u001b[43melem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1650\u001b[39m \u001b[43m    \u001b[49m\u001b[43mextracted_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1651\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_hit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_hit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1652\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1653\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_events:\n\u001b[32m   1654\u001b[39m     \u001b[38;5;28mself\u001b[39m.dispatch.after_execute(\n\u001b[32m   1655\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1656\u001b[39m         elem,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1660\u001b[39m         ret,\n\u001b[32m   1661\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1846\u001b[39m, in \u001b[36mConnection._execute_context\u001b[39m\u001b[34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[39m\n\u001b[32m   1844\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exec_insertmany_context(dialect, context)\n\u001b[32m   1845\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1846\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_exec_single_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1847\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\n\u001b[32m   1848\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1986\u001b[39m, in \u001b[36mConnection._exec_single_context\u001b[39m\u001b[34m(self, dialect, context, statement, parameters)\u001b[39m\n\u001b[32m   1983\u001b[39m     result = context._setup_result_proxy()\n\u001b[32m   1985\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m-> \u001b[39m\u001b[32m1986\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handle_dbapi_exception\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1987\u001b[39m \u001b[43m        \u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[32m   1988\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1990\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:2355\u001b[39m, in \u001b[36mConnection._handle_dbapi_exception\u001b[39m\u001b[34m(self, e, statement, parameters, cursor, context, is_sub_exec)\u001b[39m\n\u001b[32m   2353\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m should_wrap:\n\u001b[32m   2354\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m sqlalchemy_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2355\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m sqlalchemy_exception.with_traceback(exc_info[\u001b[32m2\u001b[39m]) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m   2356\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2357\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m exc_info[\u001b[32m1\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sqlalchemy\\engine\\base.py:1967\u001b[39m, in \u001b[36mConnection._exec_single_context\u001b[39m\u001b[34m(self, dialect, context, statement, parameters)\u001b[39m\n\u001b[32m   1965\u001b[39m                 \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1966\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[32m-> \u001b[39m\u001b[32m1967\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdo_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1968\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstr_statement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meffective_parameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[32m   1969\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1971\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.engine._has_events:\n\u001b[32m   1972\u001b[39m     \u001b[38;5;28mself\u001b[39m.dispatch.after_cursor_execute(\n\u001b[32m   1973\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1974\u001b[39m         cursor,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1978\u001b[39m         context.executemany,\n\u001b[32m   1979\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sqlalchemy\\engine\\default.py:951\u001b[39m, in \u001b[36mDefaultDialect.do_execute\u001b[39m\u001b[34m(self, cursor, statement, parameters, context)\u001b[39m\n\u001b[32m    950\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m951\u001b[39m     \u001b[43mcursor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mIntegrityError\u001b[39m: (psycopg2.errors.UniqueViolation) duplicate key value violates unique constraint \"dim_date_pkey\"\nDETAIL:  Key (date_sk)=(1) already exists.\n\n[SQL: \n        INSERT INTO analytics.dim_date (\n            date_sk, full_date, year, month, day,\n            day_of_week, month_name, day_name\n        )\n        SELECT\n            ROW_NUMBER() OVER (ORDER BY full_date_clean),\n            full_date_clean,\n            EXTRACT(YEAR FROM full_date_clean),\n            EXTRACT(MONTH FROM full_date_clean),\n            EXTRACT(DAY FROM full_date_clean),\n            EXTRACT(DOW FROM full_date_clean) + 1,\n            TO_CHAR(full_date_clean, 'Month'),\n            TO_CHAR(full_date_clean, 'Day')\n        FROM (\n            SELECT DISTINCT DATE_TRUNC('day', order_purchase_timestamp::timestamp)\n            AS full_date_clean\n            FROM analytics.df_orders\n        ) AS unique_dates;\n    ]\n(Background on this error at: https://sqlalche.me/e/20/gkpj)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import text\n",
    "from connection import get_engine\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# DiretÃ³rios\n",
    "NOTEBOOK_DIR = Path(os.getcwd())\n",
    "DATA_DIR = NOTEBOOK_DIR.parent / \"data\"\n",
    "ORDERS_PATH = DATA_DIR / \"olist_orders_dataset.csv\"\n",
    "\n",
    "def load_dim_date():\n",
    "    engine = get_engine()\n",
    "    print(\"Conectado ao banco!\")\n",
    "\n",
    "    # 1. Ler CSV\n",
    "    print(f\"Lendo: {ORDERS_PATH}\")\n",
    "    df_orders = pd.read_csv(ORDERS_PATH)\n",
    "\n",
    "    # padronizar colunas\n",
    "    df_orders.columns = [c.lower().strip().replace(\" \", \"_\") for c in df_orders.columns]\n",
    "\n",
    "    # 2. Criar tabela temporÃ¡ria no schema analytics\n",
    "    df_orders.to_sql(\n",
    "        \"df_orders\",\n",
    "        engine,\n",
    "        schema=\"analytics\",\n",
    "        if_exists=\"replace\",\n",
    "        index=False\n",
    "    )\n",
    "    print(\"Tabela temporÃ¡ria analytics.df_orders criada!\")\n",
    "\n",
    "    # 3. Inserir dados na dim_date\n",
    "    insert_sql = text(\"\"\"\n",
    "        INSERT INTO analytics.dim_date (\n",
    "            date_sk, full_date, year, month, day,\n",
    "            day_of_week, month_name, day_name\n",
    "        )\n",
    "        SELECT\n",
    "            ROW_NUMBER() OVER (ORDER BY full_date_clean),\n",
    "            full_date_clean,\n",
    "            EXTRACT(YEAR FROM full_date_clean),\n",
    "            EXTRACT(MONTH FROM full_date_clean),\n",
    "            EXTRACT(DAY FROM full_date_clean),\n",
    "            EXTRACT(DOW FROM full_date_clean) + 1,\n",
    "            TO_CHAR(full_date_clean, 'Month'),\n",
    "            TO_CHAR(full_date_clean, 'Day')\n",
    "        FROM (\n",
    "            SELECT DISTINCT DATE_TRUNC('day', order_purchase_timestamp::timestamp)\n",
    "            AS full_date_clean\n",
    "            FROM analytics.df_orders\n",
    "        ) AS unique_dates;\n",
    "    \"\"\")\n",
    "\n",
    "    with engine.begin() as conn:\n",
    "        conn.execute(insert_sql)\n",
    "\n",
    "    print(\"dim_date populada com sucesso!\")\n",
    "\n",
    "    # 4. Remover tabela temporÃ¡ria\n",
    "    with engine.begin() as conn:\n",
    "        conn.execute(text(\"DROP TABLE IF EXISTS analytics.df_orders;\"))\n",
    "\n",
    "    print(\"Tabela temporÃ¡ria removida!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    load_dim_date()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60f478a-1c13-4e03-8fec-0808c3c1a71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import text\n",
    "from connection import get_engine\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# DiretÃ³rios\n",
    "NOTEBOOK_DIR = Path(os.getcwd())\n",
    "DATA_DIR = NOTEBOOK_DIR.parent / \"data\"\n",
    "CUSTOMERS_PATH = DATA_DIR / \"olist_customers_dataset.csv\"\n",
    "\n",
    "def load_dim_customer():\n",
    "    engine = get_engine()\n",
    "    print(\"Conectado ao banco!\")\n",
    "\n",
    "    # 1. Ler CSV\n",
    "    print(f\"Lendo: {CUSTOMERS_PATH}\")\n",
    "    df_customers = pd.read_csv(CUSTOMERS_PATH)\n",
    "\n",
    "    # padronizar colunas\n",
    "    df_customers.columns = [c.lower().strip().replace(\" \", \"_\") for c in df_customers.columns]\n",
    "\n",
    "    # 2. Criar tabela temporÃ¡ria no schema analytics\n",
    "    df_customers.to_sql(\n",
    "        \"df_customers\",\n",
    "        engine,\n",
    "        schema=\"analytics\",\n",
    "        if_exists=\"replace\",\n",
    "        index=False\n",
    "    )\n",
    "    print(\"Tabela temporÃ¡ria analytics.df_customers criada!\")\n",
    "\n",
    "    # 3. Inserir dados na dim_customer\n",
    "    insert_sql = text(\"\"\"\n",
    "        INSERT INTO analytics.dim_customer (\n",
    "            customer_id,\n",
    "            customer_unique_id,\n",
    "            customer_zip_code_prefix,\n",
    "            customer_city,\n",
    "            customer_state\n",
    "        )\n",
    "        SELECT\n",
    "            customer_id,\n",
    "            customer_unique_id,\n",
    "            customer_zip_code_prefix,\n",
    "            customer_city,\n",
    "            customer_state\n",
    "        FROM analytics.df_customers;\n",
    "    \"\"\")\n",
    "\n",
    "    with engine.begin() as conn:\n",
    "        conn.execute(insert_sql)\n",
    "\n",
    "    print(\"dim_customer populada com sucesso!\")\n",
    "\n",
    "    # 4. Remover tabela temporÃ¡ria\n",
    "    with engine.begin() as conn:\n",
    "        conn.execute(text(\"DROP TABLE IF EXISTS analytics.df_customers;\"))\n",
    "\n",
    "    print(\"Tabela temporÃ¡ria removida!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    load_dim_customer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c463b0d-74d2-4448-be23-6d81dd09c878",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import text\n",
    "from connection import get_engine\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# DiretÃ³rios\n",
    "NOTEBOOK_DIR = Path(os.getcwd())\n",
    "DATA_DIR = NOTEBOOK_DIR.parent / \"data\"\n",
    "SELLERS_PATH = DATA_DIR / \"olist_sellers_dataset.csv\"\n",
    "\n",
    "def load_dim_seller():\n",
    "    engine = get_engine()\n",
    "    print(\"Conectado ao banco!\")\n",
    "\n",
    "    # 1. Ler CSV\n",
    "    print(f\"Lendo: {SELLERS_PATH}\")\n",
    "    df_sellers = pd.read_csv(SELLERS_PATH)\n",
    "\n",
    "    # padronizar nomes de colunas\n",
    "    df_sellers.columns = [c.lower().strip().replace(\" \", \"_\") for c in df_sellers.columns]\n",
    "\n",
    "    # 2. Criar tabela temporÃ¡ria no schema analytics\n",
    "    df_sellers.to_sql(\n",
    "        \"df_sellers\",\n",
    "        engine,\n",
    "        schema=\"analytics\",\n",
    "        if_exists=\"replace\",\n",
    "        index=False\n",
    "    )\n",
    "    print(\"Tabela temporÃ¡ria analytics.df_sellers criada!\")\n",
    "\n",
    "    # 3. Inserir dados na dim_seller\n",
    "    insert_sql = text(\"\"\"\n",
    "        INSERT INTO analytics.dim_seller (\n",
    "            seller_id,\n",
    "            seller_zip_code_prefix,\n",
    "            seller_city,\n",
    "            seller_state\n",
    "        )\n",
    "        SELECT\n",
    "            seller_id,\n",
    "            seller_zip_code_prefix,\n",
    "            seller_city,\n",
    "            seller_state\n",
    "        FROM analytics.df_sellers;\n",
    "    \"\"\")\n",
    "\n",
    "    with engine.begin() as conn:\n",
    "        conn.execute(insert_sql)\n",
    "\n",
    "    print(\"dim_seller populada com sucesso!\")\n",
    "\n",
    "    # 4. Remover tabela temporÃ¡ria\n",
    "    with engine.begin() as conn:\n",
    "        conn.execute(text(\"DROP TABLE IF EXISTS analytics.df_sellers;\"))\n",
    "\n",
    "    print(\"Tabela temporÃ¡ria removida!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    load_dim_seller()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6615c7-5b96-4114-a1fa-ef13064d89e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import text\n",
    "from connection import get_engine\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# DiretÃ³rios\n",
    "NOTEBOOK_DIR = Path(os.getcwd())\n",
    "DATA_DIR = NOTEBOOK_DIR.parent / \"data\"\n",
    "PRODUCTS_PATH = DATA_DIR / \"olist_products_dataset.csv\"\n",
    "\n",
    "def load_dim_product():\n",
    "    engine = get_engine()\n",
    "    print(\"Conectado ao banco!\")\n",
    "\n",
    "    # 1. Ler CSV\n",
    "    print(f\"Lendo: {PRODUCTS_PATH}\")\n",
    "    df_products = pd.read_csv(PRODUCTS_PATH)\n",
    "\n",
    "    # padronizar nomes das colunas\n",
    "    df_products.columns = [c.lower().strip().replace(\" \", \"_\") for c in df_products.columns]\n",
    "\n",
    "    # 2. Criar tabela temporÃ¡ria df_products no schema analytics\n",
    "    df_products.to_sql(\n",
    "        \"df_products\",\n",
    "        engine,\n",
    "        schema=\"analytics\",\n",
    "        if_exists=\"replace\",\n",
    "        index=False\n",
    "    )\n",
    "    print(\"Tabela temporÃ¡ria analytics.df_products criada!\")\n",
    "\n",
    "    # 3. Inserir dados na dim_product\n",
    "    insert_sql = text(\"\"\"\n",
    "        INSERT INTO analytics.dim_product (\n",
    "            product_id,\n",
    "            product_category_name,\n",
    "            product_name_lenght,\n",
    "            product_description_lenght,\n",
    "            product_photos_qty,\n",
    "            product_weight_g,\n",
    "            product_length_cm,\n",
    "            product_height_cm,\n",
    "            product_width_cm\n",
    "        )\n",
    "        SELECT\n",
    "            product_id,\n",
    "            product_category_name,\n",
    "            product_name_lenght,\n",
    "            product_description_lenght,\n",
    "            product_photos_qty,\n",
    "            product_weight_g,\n",
    "            product_length_cm,\n",
    "            product_height_cm,\n",
    "            product_width_cm\n",
    "        FROM analytics.df_products;\n",
    "    \"\"\")\n",
    "\n",
    "    with engine.begin() as conn:\n",
    "        conn.execute(insert_sql)\n",
    "\n",
    "    print(\"dim_product populada com sucesso!\")\n",
    "\n",
    "    # 4. Remover tabela temporÃ¡ria\n",
    "    with engine.begin() as conn:\n",
    "        conn.execute(text(\"DROP TABLE IF EXISTS analytics.df_products;\"))\n",
    "\n",
    "    print(\"Tabela temporÃ¡ria removida!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    load_dim_product()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d3356dc-c91a-43b5-aa6a-1152e654856c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”Œ Conectado ao banco!\n",
      "ðŸ“„ Carregando arquivos...\n",
      "ðŸ“Œ Criando tabelas temporÃ¡rias...\n",
      "âœ… Tabelas temporÃ¡rias criadas!\n",
      "ðŸ“¥ Inserindo dados na fact_sales...\n",
      "ðŸŽ‰ Dados inseridos com sucesso na fact_sales!\n",
      "ðŸ§¹ Limpando tabelas temporÃ¡rias...\n",
      "ðŸš€ Processo finalizado!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import text\n",
    "from connection import get_engine\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# DiretÃ³rio do notebook\n",
    "NOTEBOOK_DIR = Path(os.getcwd())\n",
    "DATA_DIR = NOTEBOOK_DIR.parent / \"data\"\n",
    "\n",
    "# Arquivos\n",
    "ORDERS_PATH = DATA_DIR / \"olist_orders_dataset.csv\"\n",
    "ITEMS_PATH = DATA_DIR / \"olist_order_items_dataset.csv\"\n",
    "\n",
    "\n",
    "def load_fact_sales():\n",
    "    engine = get_engine()\n",
    "    print(\"ðŸ”Œ Conectado ao banco!\")\n",
    "\n",
    "    # =====================================================\n",
    "    # 1. Ler os CSVs\n",
    "    # =====================================================\n",
    "    print(\"ðŸ“„ Carregando arquivos...\")\n",
    "    df_orders = pd.read_csv(ORDERS_PATH)\n",
    "    df_items = pd.read_csv(ITEMS_PATH)\n",
    "\n",
    "    # =====================================================\n",
    "    # 2. Padronizar nomes\n",
    "    # =====================================================\n",
    "    df_orders.columns = [c.lower().strip().replace(\" \", \"_\") for c in df_orders.columns]\n",
    "    df_items.columns = [c.lower().strip().replace(\" \", \"_\") for c in df_items.columns]\n",
    "\n",
    "    # =====================================================\n",
    "    # 3. Criar Tabelas TemporÃ¡rias\n",
    "    # =====================================================\n",
    "    print(\"ðŸ“Œ Criando tabelas temporÃ¡rias...\")\n",
    "\n",
    "    df_orders.to_sql(\n",
    "        \"temp_orders\",\n",
    "        engine,\n",
    "        schema=\"analytics\",\n",
    "        if_exists=\"replace\",\n",
    "        index=False\n",
    "    )\n",
    "\n",
    "    df_items.to_sql(\n",
    "        \"temp_items\",\n",
    "        engine,\n",
    "        schema=\"analytics\",\n",
    "        if_exists=\"replace\",\n",
    "        index=False\n",
    "    )\n",
    "\n",
    "    print(\"âœ… Tabelas temporÃ¡rias criadas!\")\n",
    "\n",
    "    # =====================================================\n",
    "    # 4. InserÃ§Ã£o com CASTs seguros\n",
    "    # =====================================================\n",
    "\n",
    "    insert_sql = text(\"\"\"\n",
    "        INSERT INTO analytics.fact_sales (\n",
    "            order_id,\n",
    "            customer_id,\n",
    "            order_purchase_timestamp,\n",
    "            order_item,\n",
    "            product_id,\n",
    "            seller_id,\n",
    "            shipping_limit_date,\n",
    "            price,\n",
    "            freight_value\n",
    "        )\n",
    "        SELECT\n",
    "            o.order_id,\n",
    "            o.customer_id,\n",
    "            o.order_purchase_timestamp::timestamp,\n",
    "            i.order_item_id::integer,\n",
    "            i.product_id,\n",
    "            i.seller_id,\n",
    "            i.shipping_limit_date::timestamp,\n",
    "            i.price::numeric,\n",
    "            i.freight_value::numeric\n",
    "        FROM analytics.temp_orders o\n",
    "        JOIN analytics.temp_items i\n",
    "            ON o.order_id = i.order_id;\n",
    "    \"\"\")\n",
    "\n",
    "    print(\"ðŸ“¥ Inserindo dados na fact_sales...\")\n",
    "\n",
    "    with engine.begin() as conn:\n",
    "        conn.execute(insert_sql)\n",
    "\n",
    "    print(\"ðŸŽ‰ Dados inseridos com sucesso na fact_sales!\")\n",
    "\n",
    "    # =====================================================\n",
    "    # 5. Remover tabelas temporÃ¡rias\n",
    "    # =====================================================\n",
    "    print(\"ðŸ§¹ Limpando tabelas temporÃ¡rias...\")\n",
    "\n",
    "    with engine.begin() as conn:\n",
    "        conn.execute(text(\"DROP TABLE IF EXISTS analytics.temp_orders;\"))\n",
    "        conn.execute(text(\"DROP TABLE IF EXISTS analytics.temp_items;\"))\n",
    "\n",
    "    print(\"ðŸš€ Processo finalizado!\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    load_fact_sales()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c38c2c-f15e-4543-b711-7dc0ba926bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import text\n",
    "\n",
    "for t in [\"df_orders\", \"df_items\"]:\n",
    "    r = con.execute(text(f\"\"\"\n",
    "    SELECT COUNT(*) FROM analytics.{t};\n",
    "    \"\"\")).fetchone()\n",
    "    print(t, r[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cbc6b5-801f-4ea6-8682-663e01ce9a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = con.execute(text(\"\"\"\n",
    "SELECT COUNT(*)\n",
    "FROM analytics.df_orders o\n",
    "JOIN analytics.df_items i\n",
    "    ON o.order_id = i.order_id;\n",
    "\"\"\")).fetchone()\n",
    "\n",
    "print(\"Linhas retornadas pelo JOIN:\", r[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "135554a8-9561-4876-9d2b-4d3b4071987e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Carregando CSVs...\n",
      "\n",
      "ðŸ§µ Colunas dos arquivos:\n",
      "df_orders: ['order_id', 'customer_id', 'order_status', 'order_purchase_timestamp', 'order_approved_at', 'order_delivered_carrier_date', 'order_delivered_customer_date', 'order_estimated_delivery_date']\n",
      "df_items: ['order_id', 'order_item_id', 'product_id', 'seller_id', 'shipping_limit_date', 'price', 'freight_value']\n",
      "\n",
      "ðŸ”  Colunas apÃ³s padronizaÃ§Ã£o:\n",
      "df_orders: ['order_id', 'customer_id', 'order_status', 'order_purchase_timestamp', 'order_approved_at', 'order_delivered_carrier_date', 'order_delivered_customer_date', 'order_estimated_delivery_date']\n",
      "df_items: ['order_id', 'order_item_id', 'product_id', 'seller_id', 'shipping_limit_date', 'price', 'freight_value']\n",
      "\n",
      "ðŸ” Tipos das colunas order_id:\n",
      "df_orders.order_id: object\n",
      "df_items.order_id: object\n",
      "\n",
      "ðŸ” Exemplos de order_id:\n",
      "df_orders: 0    e481f51cbdc54678b7cc49136f2d6af7\n",
      "1    53cdb2fc8bc7dce0b6741e2150273451\n",
      "2    47770eb9100c2d0c44946d9cf07ec65d\n",
      "3    949d5b44dbf5de918fe9c16f97b45f8a\n",
      "4    ad21c59c0840e6cb83a9ceb5573f8159\n",
      "Name: order_id, dtype: object\n",
      "df_items: 0    00010242fe8c5a6d1ba2dd792cb16214\n",
      "1    00018f77f2f0320c557190d7a144bdd3\n",
      "2    000229ec398224ef6ca0657da4fc703e\n",
      "3    00024acbcdf0a6daa1e931b038114c75\n",
      "4    00042b26cf59d7ce69dfabb4e55b4fd9\n",
      "Name: order_id, dtype: object\n",
      "\n",
      "ðŸ“Š Quantidade de IDs:\n",
      "IDs Ãºnicos em df_orders: 99441\n",
      "IDs Ãºnicos em df_items: 98666\n",
      "\n",
      "ðŸ§© Quantidade de order_id que existem nos DOIS CSVs: 98666\n",
      "\n",
      "ðŸ§© 10 valores que batem:\n",
      "['9403f186541e5cfa0b72d67be22cb81a', 'bdf132cfee5c1e0674b5b27eaf076f71', 'b436fd24a04e7267307e1d900faa8eb1', '0922de4af18de92fdca6fed66b34b66f', '8fc274ece82e47a7664b5bea315acf02', 'd22c571279d3726b807c6ac4562a3479', '4969cddf1cd3a57ea95fe8c3b89a7018', 'ea2a61e3a57414402f9c6dae7b04cddd', '52432d42fb818ca588e38c5067f73c3f', '94cf59885365bee1e40724968aa2f524']\n",
      "\n",
      "ðŸ”Œ Testando direto no banco...\n",
      "\n",
      "ðŸ“¥ Resultado do JOIN no banco: 112650\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import text\n",
    "from connection import get_engine\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# DiretÃ³rio atual do notebook\n",
    "NOTEBOOK_DIR = Path(os.getcwd())\n",
    "DATA_DIR = NOTEBOOK_DIR.parent / \"data\"\n",
    "\n",
    "ORDERS_PATH = DATA_DIR / \"olist_orders_dataset.csv\"\n",
    "ITEMS_PATH = DATA_DIR / \"olist_order_items_dataset.csv\"\n",
    "\n",
    "# ============================================================\n",
    "# 1) Carregar CSVs e mostrar informaÃ§Ãµes importantes\n",
    "# ============================================================\n",
    "\n",
    "print(\"ðŸ“„ Carregando CSVs...\")\n",
    "df_orders = pd.read_csv(ORDERS_PATH)\n",
    "df_items = pd.read_csv(ITEMS_PATH)\n",
    "\n",
    "print(\"\\nðŸ§µ Colunas dos arquivos:\")\n",
    "print(\"df_orders:\", df_orders.columns.tolist())\n",
    "print(\"df_items:\", df_items.columns.tolist())\n",
    "\n",
    "# padronizar nomes\n",
    "df_orders.columns = [c.lower().strip().replace(\" \", \"_\") for c in df_orders.columns]\n",
    "df_items.columns = [c.lower().strip().replace(\" \", \"_\") for c in df_items.columns]\n",
    "\n",
    "print(\"\\nðŸ”  Colunas apÃ³s padronizaÃ§Ã£o:\")\n",
    "print(\"df_orders:\", df_orders.columns.tolist())\n",
    "print(\"df_items:\", df_items.columns.tolist())\n",
    "\n",
    "# ============================================================\n",
    "# 2) DiagnÃ³stico dos tipos e exemplos de valores\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\nðŸ” Tipos das colunas order_id:\")\n",
    "print(\"df_orders.order_id:\", df_orders[\"order_id\"].dtype)\n",
    "print(\"df_items.order_id:\", df_items[\"order_id\"].dtype)\n",
    "\n",
    "print(\"\\nðŸ” Exemplos de order_id:\")\n",
    "print(\"df_orders:\", df_orders[\"order_id\"].dropna().head())\n",
    "print(\"df_items:\", df_items[\"order_id\"].dropna().head())\n",
    "\n",
    "# ============================================================\n",
    "# 3) Ver quantos order_id existem em cada tabela\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\nðŸ“Š Quantidade de IDs:\")\n",
    "print(\"IDs Ãºnicos em df_orders:\", df_orders[\"order_id\"].nunique())\n",
    "print(\"IDs Ãºnicos em df_items:\", df_items[\"order_id\"].nunique())\n",
    "\n",
    "# ============================================================\n",
    "# 4) Ver quantos order_id realmente batem entre os arquivos\n",
    "# ============================================================\n",
    "\n",
    "orders_set = set(df_orders[\"order_id\"].astype(str))\n",
    "items_set = set(df_items[\"order_id\"].astype(str))\n",
    "\n",
    "intersection = orders_set.intersection(items_set)\n",
    "\n",
    "print(\"\\nðŸ§© Quantidade de order_id que existem nos DOIS CSVs:\", len(intersection))\n",
    "\n",
    "if len(intersection) > 0:\n",
    "    print(\"\\nðŸ§© 10 valores que batem:\")\n",
    "    print(list(intersection)[:10])\n",
    "\n",
    "# ============================================================\n",
    "# 5) DiagnÃ³stico direto no banco (se tabelas temporÃ¡rias jÃ¡ existirem)\n",
    "# ============================================================\n",
    "\n",
    "engine = get_engine()\n",
    "print(\"\\nðŸ”Œ Testando direto no banco...\")\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(text(\"\"\"\n",
    "        SELECT COUNT(*) \n",
    "        FROM analytics.df_orders o\n",
    "        JOIN analytics.df_items i\n",
    "            ON o.order_id = i.order_id;\n",
    "    \"\"\"))\n",
    "    print(\"\\nðŸ“¥ Resultado do JOIN no banco:\", result.scalar())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ec2866-c961-4b25-8054-616bc1ca8ba3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
